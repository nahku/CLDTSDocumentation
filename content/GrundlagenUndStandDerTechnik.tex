%!TEX root = ../dokumentation.tex

\chapter{Background and Theory}\label{cha:Background}



\cite{Mogensen.2017}
Compiler: Translate (high-level) programming language into machine language

\section{TPTP Language}\label{sec:BackgroundTPTP}
The \acf{TPTP} is a library of problems for automated \ac{ATP}.
Problems within the library are described in the \ac{TPTP} language.
The  \ac{TPTP} language is a formal language and its grammar is specified in an \ac{EBNF}. \cite{Sut17}\\
The \ac{EBNF} \cite{EBNF} is a todo and is used to describe \acp{CFG}.

%\section{\acf{BNF}}\label{sec:BackgroundBNF}

\section{Compiler}\label{sec:BackgroundCompiler}

\cite{Mogensen.2017}
Compiler: Translate (high-level) programming language into machine language

Different phases for writing a compiler, phases are processed sequently

\section{Lexer}\label{sec:BackgroundLexer}

Lexing or a so called lexical analysis is the division of input into units so called tokens \cite{LexYacc.1992}. 
The input is a string containing a sequence of characters. 
Often, the lexer is generated by a lexer generator and not written manually.
When writing the lexer manually TODO
A lexer generator takes a specification of tokens as input and generates the lexer automatically. 
The specification is usually written using regular expressions. 
A regular expression describes a formal language and can be described by a finite automata.
A formal language describes a set of words belongig to the language.
These words are built over the alphabet of the language.
Shorthands are common to simplify a regular expression.
For example all alphabetic letters in lower and upper case are combined and represented by [a-zA-Z].
The same principle can be also be applied to represent a set of numbers.
However, using not clearly defined intervals e.g. [0-b] is not common as it has different interpretations by different lexer generators and thus can lead to mistakes. \cite{Mogensen.2017}

A lexer needs to distinguish different types of tokens and furthermore decide which token to use if there are multiple ones that fit the input. \cite{Mogensen.2017}

A simple approach to build a lexer to to build an automata for each token definition and then test to which automata the input correspondends.
However, this would be slow as all automatas need to be passed through in the worst case.
Therefore, it is convenient to build a single automata that tests each token simultaneously.
This automata can be build by combining all regular expressions by disjunction.
Each final state from each regular expression is marked to know which token has been identified.

It is possible, that final states overlap as a consequence of one token being a subset of another token.
For solving such conflicts a precendence of tokens can be declared. Usually the token that is being definded the earliest has a higher precende and thus will be chosen if multiple tokens fit the input. \cite{Mogensen.2017}

Another task of the lexer is seperating the input in order to divide it into tokens.
Per convention the longest input that matches any token is chosen. \cite{Mogensen.2017}


%Input: description of tokens - lex specification, regular expressions]\cite{LexYacc.1992}
%Output: routine that identifies those tokens \cite{LexYacc.1992}

%Tokens are for example variable names or keywords. 

%Each token corresponds to a symbol in the programming language

%A lexer takes a string containing a sequence of chararacters as input and divides this input into units so called tokens. 

\section{Parser}\label{sec:BackgroundParser}
\subsection{Yacc}\label{sec:BackgroundYacc}

Building a syntax tree out of the generated tokens \cite{Mogensen.2017}

Parsing: establish relationship among tokens \cite{LexYacc.1992}
Grammar: list of rules that defines the relationships \cite{LexYacc.1992}

Input: description of grammar \cite{LexYacc.1992}
Output: parser \cite{LexYacc.1992}


\subsection{PLY}\label{sec:BackgroundPLY}

\acf{PLY} \cite{PLY} is an implementation of lex and yacc in python.
[LALR-parsing]
consists of lex.py and yacc.py

lex.py tokenizes an input string


\subsection{Nondeterministic Finite Automata}\label{sec:BackgroundNDAutomata}

\section{Python?}\label{sec:BackgroundPython}